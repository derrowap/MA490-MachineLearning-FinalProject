{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Attempt to Mimic Several Functions\n",
    "#### Team Leader: Austin Derrow-Pinion\n",
    "#### Team Members: Kice Sanders, Aaron Bartee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    " \n",
    " * [Executive Summary](#Executive-Summary)\n",
    " * [Links](#Links)\n",
    " * [Supplement](ProjectReportSupplement.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executive Summary\n",
    "In this study, we attempt to compare the power of neural networksâ€™ ability to mimic functions with the functions themselves. The Universal Approximation Theorem states that for any continuous function, there exists a feed-forward network with only a single hidden layer that can approximate it. This is motivation for us to try out different functions and try to train a neural network to accurately approximate as many as we can. For functions that are not approximated well, we can observe the function and try to learn more about neural networks as to why it did not learn the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "The overall objective is to explore the complexity of problems which are able to be solved by applying learning with neural networks. We have programmed several different functions in Python, all of which range in complexity. We can have a loop that feeds in a very large number of inputs to these functions and records the output in order to generate a large amount of data. The programs were made by us so we can generate as much data as we need to train the neural network. \n",
    "\n",
    "With this data, we will use supervised learning by feeding the network with the input data and using back-propagation to update the weights in the network. The neural network will be programmed using TensorFlow. We have been going through tutorials on TensorFlow to learn how to use it, but have not been able to learn how to use this kind of neural network just yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "Since all functions are written by us, we are able to randomly generate inputs for each function and record the output. This allows us to have as much data as needed to observe the performance of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[         11          89]\n",
      " [         54 86267571272]\n",
      " [          5           5]\n",
      " [         42   267914296]\n",
      " [         50 12586269025]\n",
      " [          1           1]\n",
      " [         34     5702887]\n",
      " [          4           3]\n",
      " [         52 32951280099]\n",
      " [         15         610]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from trainingFunctions import *\n",
    "\n",
    "# fill an 2D array, mapping inputs to the fib function\n",
    "# to the output of the fib function\n",
    "TRAINING_EXAMPLES = 10\n",
    "fib_example = np.ndarray(shape=(TRAINING_EXAMPLES,2), dtype='int64')\n",
    "for x in range(len(fib_example)):\n",
    "    input_ = int(np.random.randint(1,70))\n",
    "    fib_example[x,] = [input_, fib(input_)]\n",
    "print(fib_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1128    0]\n",
      " [1782    0]\n",
      " [1569    0]\n",
      " [1514    1]\n",
      " [1586    1]\n",
      " [ 515    1]\n",
      " [ 908    1]\n",
      " [1861    0]\n",
      " [1057    1]\n",
      " [1584    0]]\n"
     ]
    }
   ],
   "source": [
    "# fill an 2D array, mapping inputs to the evenParity function\n",
    "# to the output of the evenParity function\n",
    "TRAINING_EXAMPLES = 10\n",
    "evenParity_example = np.ndarray(shape=(TRAINING_EXAMPLES,2), dtype='int64')\n",
    "for x in range(len(evenParity_example)):\n",
    "    input_ = int(np.random.randint(1,2000))\n",
    "    evenParity_example[x,] = [input_, evenParity(input_)]\n",
    "print(evenParity_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1785    1]\n",
      " [ 668    0]\n",
      " [1269    0]\n",
      " [1322    0]\n",
      " [ 416    0]\n",
      " [1031    1]\n",
      " [ 899    0]\n",
      " [ 535    0]\n",
      " [ 786    1]\n",
      " [1720    1]]\n"
     ]
    }
   ],
   "source": [
    "# fill an 2D array, mapping inputs to the oddParity function\n",
    "# to the output of the oddParity function\n",
    "TRAINING_EXAMPLES = 10\n",
    "oddParity_example = np.ndarray(shape=(TRAINING_EXAMPLES, 2), dtype='int64')\n",
    "for x in range(len(oddParity_example)):\n",
    "    input_ = int(np.random.randint(1,2000))\n",
    "    oddParity_example[x,] = [input_, oddParity(input_)]\n",
    "print(oddParity_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ctkevwcekusrdghgirfvtyrpsochayygtbbtgyyahcosprytvfrighgdrsukecwvektc', True], ['vitjgnullungjtiv', True], ['mhsicttaonvsikvqoegcrvgfkphqyof', False], ['n', True], ['nibtiugxhmiygjjgyimhxguitbin', True], ['ppuuaxipukkfhiqojwpncbcljbgqlnjdgymbynb', False], ['jvuoqsltbsjrvvtpcbdekwbgeucnfsfxscdrwsweilliewswrdcsxfsfncuegbwkedbcptvvrjsbtlsqouvj', True], ['lkxqh', False], ['musqcahvaxdeemefyvoxbbyjahdqatjclaixg', False], ['ynleyigtuapaguufmppwhtwdyyliilyydwthwppmfuugapautgiyelny', True], ['pneumonoultramicroscopicsilicovolcanoconiosissisoinoconaclovociliscipocsorcimartluonomuenp', True]]\n",
      "[[[99, 116, 107, 101, 118, 119, 99, 101, 107, 117, 115, 114, 100, 103, 104, 103, 105, 114, 102, 118, 116, 121, 114, 112, 115, 111, 99, 104, 97, 121, 121, 103, 116, 98, 98, 116, 103, 121, 121, 97, 104, 99, 111, 115, 112, 114, 121, 116, 118, 102, 114, 105, 103, 104, 103, 100, 114, 115, 117, 107, 101, 99, 119, 118, 101, 107, 116, 99], True], [[118, 105, 116, 106, 103, 110, 117, 108, 108, 117, 110, 103, 106, 116, 105, 118], True], [[109, 104, 115, 105, 99, 116, 116, 97, 111, 110, 118, 115, 105, 107, 118, 113, 111, 101, 103, 99, 114, 118, 103, 102, 107, 112, 104, 113, 121, 111, 102], False], [[110], True], [[110, 105, 98, 116, 105, 117, 103, 120, 104, 109, 105, 121, 103, 106, 106, 103, 121, 105, 109, 104, 120, 103, 117, 105, 116, 98, 105, 110], True], [[112, 112, 117, 117, 97, 120, 105, 112, 117, 107, 107, 102, 104, 105, 113, 111, 106, 119, 112, 110, 99, 98, 99, 108, 106, 98, 103, 113, 108, 110, 106, 100, 103, 121, 109, 98, 121, 110, 98], False], [[106, 118, 117, 111, 113, 115, 108, 116, 98, 115, 106, 114, 118, 118, 116, 112, 99, 98, 100, 101, 107, 119, 98, 103, 101, 117, 99, 110, 102, 115, 102, 120, 115, 99, 100, 114, 119, 115, 119, 101, 105, 108, 108, 105, 101, 119, 115, 119, 114, 100, 99, 115, 120, 102, 115, 102, 110, 99, 117, 101, 103, 98, 119, 107, 101, 100, 98, 99, 112, 116, 118, 118, 114, 106, 115, 98, 116, 108, 115, 113, 111, 117, 118, 106], True], [[108, 107, 120, 113, 104], False], [[109, 117, 115, 113, 99, 97, 104, 118, 97, 120, 100, 101, 101, 109, 101, 102, 121, 118, 111, 120, 98, 98, 121, 106, 97, 104, 100, 113, 97, 116, 106, 99, 108, 97, 105, 120, 103], False], [[121, 110, 108, 101, 121, 105, 103, 116, 117, 97, 112, 97, 103, 117, 117, 102, 109, 112, 112, 119, 104, 116, 119, 100, 121, 121, 108, 105, 105, 108, 121, 121, 100, 119, 116, 104, 119, 112, 112, 109, 102, 117, 117, 103, 97, 112, 97, 117, 116, 103, 105, 121, 101, 108, 110, 121], True], [[112, 110, 101, 117, 109, 111, 110, 111, 117, 108, 116, 114, 97, 109, 105, 99, 114, 111, 115, 99, 111, 112, 105, 99, 115, 105, 108, 105, 99, 111, 118, 111, 108, 99, 97, 110, 111, 99, 111, 110, 105, 111, 115, 105, 115, 115, 105, 115, 111, 105, 110, 111, 99, 111, 110, 97, 99, 108, 111, 118, 111, 99, 105, 108, 105, 115, 99, 105, 112, 111, 99, 115, 111, 114, 99, 105, 109, 97, 114, 116, 108, 117, 111, 110, 111, 109, 117, 101, 110, 112], True]]\n"
     ]
    }
   ],
   "source": [
    "# Get training data for the isPalindrome function\n",
    "# using a range of letters from 'a' to 'z' (97 - 122)\n",
    "\n",
    "TRAINING_EXAMPLES = 10\n",
    "readable_data = []\n",
    "real_data = []\n",
    "for x in range(TRAINING_EXAMPLES):\n",
    "    # generate 10 training examples\n",
    "    size_of_string = np.random.randint(1,50) # range can increase\n",
    "    input_ = [np.random.randint(97, 122) for x in range(size_of_string)]\n",
    "    if np.random.randint(1,3) == 1:\n",
    "        # half the time, make it a guaranteed palindrome\n",
    "        input_ = makePalindrome(input_)\n",
    "    output = isPalindrome(input_)\n",
    "    real_data.append([input_, output])\n",
    "    input_ = \"\".join([chr(i) for i in input_])\n",
    "    readable_data.append([input_, output])\n",
    "\n",
    "# Manually test this palindrome. A disease that causes inflammation\n",
    "# in the lungs from inhaling very fine silica dust.\n",
    "input_ = makePalindrome('pneumonoultramicroscopicsilicovolcanoconiosis')\n",
    "output = isPalindrome(input_)\n",
    "readable_data.append([input_, output])\n",
    "input_ = [ord(i) for i in input_]\n",
    "real_data.append([input_, output])\n",
    "\n",
    "print(readable_data)\n",
    "print(real_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "We define several different functions we can use to train a neural network in the [ProjectReportSupplement.ipynb](ProjectReportSupplement.ipynb) notebook.\n",
    "\n",
    "The Universal Law of Approximation is explained here: [http://neuralnetworksanddeeplearning.com/chap4.html]\n",
    "\n",
    "Our code is open sourced on GitHub here:\n",
    "[https://github.com/derrowap/MA490-MachineLearning-FinalProject/blob/master/trainingFunctions.py]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
